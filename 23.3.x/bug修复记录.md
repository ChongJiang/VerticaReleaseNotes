# 23.3.0-10 
Updated 06/07/2024
|Issue Key|Component|Description|描述|
|-|-|-|-|
VER-93195|Data load / COPY|When the Avro parser would read a byte array that is at most 8 bytes long into a numeric-typed target, it would only accept a single-word numeric as the target type. This has been resolved; now, the Avro parser supports reading short byte arrays into multi-word numeric targets.|当 Avro 解析器将长度最多为 8 个字节的字节数组读入数字类型的目标时，它只接受单字数字作为目标类型。此问题已得到解决；现在，Avro 解析器支持将短字节数组读入多字数字目标。
VER-93327|Execution Engine|User-Defined Aggregates didn't work with single distinct built-in aggregate in the same query when the input wasn't sorted on grouping columns plus distinct aggregate column. The issue has been resolved.|当输入未按分组列和不同的聚合列排序时，用户定义聚合无法与同一查询中的单个不同的内置聚合一起使用。此问题已解决。
VER-93447|Backup/DR|LocalStorageLocator did not implement the construct_new() method. When called, it fell back to the StorageLocation.construct_new() method, which raised an error. This issue has been resolved. LocalStorageLocator.construct_new() is now implemented.|LocalStorageLocator 未实现 construct_new() 方法。调用时，它会回退到 StorageLocation.construct_new() 方法，从而引发错误。此问题已解决。LocalStorageLocator.construct_new() 现已实现。
VER-93798|Optimizer|In version 23.3.0-9, queries that reused views containing WITH clauses would sometimes fail after several executions of the same query. This issue has been resolved.|在版本 23.3.0-9 中，重用包含 WITH 子句的视图的查询有时会在多次执行同一查询后失败。此问题已得到解决。
VER-93926|Execution Engine|Whether LIKE ANY / ALL read strings as UTF8 character sequences or binary byte arrays depended on whether the collation of the current locale was binary, leading to incorrect results when reading multi-character UTF8 strings in binary-collated locales. This has been resolved. Now, LIKE ANY / ALL always reads UTF8 character sequences, regardless of the current locale's collation.|LIKE ANY / ALL 是否将字符串读取为 UTF8 字符序列或二进制字节数组取决于当前语言环境的排序规则是否为二进制，这导致在二进制排序语言环境中读取多字符 UTF8 字符串时出现错误结果。此问题已解决。现在，LIKE ANY / ALL 始终读取 UTF8 字符序列，而不管当前语言环境的排序规则如何。
VER-93935|Client Drivers - ODBC|"The Windows DSN configuration utility no longer sets vertica as the default KerberosServiceName value when editing a DSN.Starting with version 11.1, providing a value causes the ODBC driver to assume the connection is using Kerberos authentication and communicates to the server that it prefers to use that authentication method, assuming that the user has a grant to a Kerberos authentication method. The KerberosServiceName value might be set in earlier versions of Windows ODBC DSNs. Clearing the value will resolve the issue. This issue only applies to users who have a Kerberos authentication method granted with a lower priority than other authentication methods and use the DSN configuration utility to set up a DSN on Windows."|编辑 DSN 时，Windows DSN 配置实用程序不再将 vertica 设置为默认的 KerberosServiceName 值。从版本 11.1 开始，提供一个值会导致 ODBC 驱动程序假定连接正在使用 Kerberos 身份验证，并向服务器传达它更喜欢使用该身份验证方法的信息，假定用户已获得 Kerberos 身份验证方法的授权。KerberosServiceName 值可能在早期版本的 Windows ODBC DSN 中设置。清除该值将解决此问题。此问题仅适用于具有比其他身份验证方法优先级更低的 Kerberos 身份验证方法并使用 DSN 配置实用程序在 Windows 上设置 DSN 的用户。
VER-94034|ComplexTypes, Kafka Integration|Loading JSON/Avro data with Kafka and Flex parsers into tables with many columns suffered from performance degradation. The performance issue has been resolved.|使用 Kafka 和 Flex 解析器将 JSON/Avro 数据加载到具有许多列的表中会导致性能下降。此性能问题已得到解决。
VER-94330|Kafka Integration|The vkconfig --refresh-interval option now functions properly. Setting it to one hour will refresh the lane worker every hour.|vkconfig --refresh-interval 选项现在可正常运行。将其设置为一小时将每小时刷新一次通道工作器。
VER-94333|Optimizer|NOT LIKE ANY and NOT LIKE ALL are consistent with PostgreSQL now - the phrases LIKE, ILIKE, NOT LIKE, and NOT ILIKE are generally treated as operators in PostgreSQL syntax.|NOT LIKE ANY 和 NOT LIKE ALL 现在与 PostgreSQL 一致 - 短语 LIKE、ILIKE、NOT LIKE 和 NOT ILIKE 在 PostgreSQL 语法中通常被视为运算符。
VER-94572|Data load / COPY|In rare cases, copying a JSON to a table using FJsonParser or KafkaJsonParser could cause the server to go down. This issue has been fixed.|在极少数情况下，使用 FJsonParser 或 KafkaJsonParser 将 JSON 复制到表可能会导致服务器瘫痪。此问题已修复。
VER-94599|FlexTable|The copy of multiple json files to Vertica table using fjsonparser() is successful now, which was causing the initiator node down issue before this fix.|现在可以使用 fjsonparser() 将多个 json 文件复制到 Vertica 表，而在此修复之前，这会导致启动器节点出现故障。
